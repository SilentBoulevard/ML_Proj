{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2450000, test size 50000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from functions import *\n",
    "\n",
    "with open('train_pos_full.txt', errors='ignore') as f:\n",
    "    content_pos = f.readlines()\n",
    "    \n",
    "with open('train_neg_full.txt', errors='ignore') as g:\n",
    "    content_neg = g.readlines()\n",
    "    \n",
    "content = []\n",
    "content.extend(content_pos)\n",
    "content.extend(content_neg)\n",
    "X = content\n",
    "Y = [1] * len(content_pos) + [0] * len(content_neg)\n",
    "data = char_preproc(X, Y, vocab_len = 100, binarize = False)\n",
    "\n",
    "\n",
    "with open('objs.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/output/objs.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('/output/objs.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN SETTING\n",
      "IN DATA GENERATION\n",
      "input shape:  (2450000, 140)\n",
      "IN MODEL CREATION\n",
      "IN FORMALITIES\n",
      "logs/2017-12-20-15-57-00_embedding\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 140, 100)          7000      \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 140, 500)          400500    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 46, 500)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 46, 500)           2000500   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 23, 500)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 23, 500)           2000500   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 23, 500)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 23, 500)           2000500   \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 23, 500)           2000500   \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 11500)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              11777024  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 20,188,574\n",
      "Trainable params: 20,188,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "IN TRAINING\n",
      "Train on 2450000 samples, validate on 50000 samples\n",
      "Epoch 1/10\n",
      "2450000/2450000 [==============================] - 464s - loss: 0.3824 - acc: 0.8182 - val_loss: 0.3287 - val_acc: 0.8583\n",
      "Epoch 2/10\n",
      "2450000/2450000 [==============================] - 464s - loss: 0.3338 - acc: 0.8529 - val_loss: 0.3162 - val_acc: 0.8636\n",
      "Epoch 3/10\n",
      "2450000/2450000 [==============================] - 464s - loss: 0.3238 - acc: 0.8585 - val_loss: 0.3196 - val_acc: 0.8601\n",
      "Epoch 4/10\n",
      "2450000/2450000 [==============================] - 464s - loss: 0.3208 - acc: 0.8609 - val_loss: 0.3118 - val_acc: 0.8660\n",
      "Epoch 5/10\n",
      "2450000/2450000 [==============================] - 464s - loss: 0.3219 - acc: 0.8629 - val_loss: 0.3163 - val_acc: 0.8668\n",
      "Epoch 6/10\n",
      "2450000/2450000 [==============================] - 464s - loss: 0.3191 - acc: 0.8642 - val_loss: 0.3608 - val_acc: 0.8591\n",
      "Epoch 7/10\n",
      "2450000/2450000 [==============================] - 464s - loss: 0.3180 - acc: 0.8655 - val_loss: 0.3551 - val_acc: 0.8553\n",
      "Epoch 8/10\n",
      "2450000/2450000 [==============================] - 464s - loss: 0.3155 - acc: 0.8667 - val_loss: 0.3416 - val_acc: 0.8647\n",
      "Epoch 9/10\n",
      "2450000/2450000 [==============================] - 464s - loss: 0.3166 - acc: 0.8674 - val_loss: 0.3168 - val_acc: 0.8672\n",
      "Epoch 10/10\n",
      "2450000/2450000 [==============================] - 464s - loss: 0.3188 - acc: 0.8676 - val_loss: 0.3175 - val_acc: 0.8678\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Conv1D, MaxPooling1D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from functions import *\n",
    "\n",
    "\n",
    "# conf and preprocess -----------------------------------------\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# settings ---------------------\n",
    "# ------------------------------\n",
    "print('IN SETTING')\n",
    "EMBEDDING = True\n",
    "TYPE = 'embedding' if EMBEDDING else 'standard'\n",
    "MODELPATH ='models/char-conv-' + TYPE + '-{epoch:02d}-{val_acc:.3f}-{val_loss:.3f}.hdf5'\n",
    "FILTERS = 500\n",
    "LR = 0.0001 if EMBEDDING else 0.00001\n",
    "\n",
    "CONV = [\n",
    "    {'filters':200, 'kernel':8, 'strides':1, 'padding':'same', 'reg': 0, 'pool':3},\n",
    "    {'filters':200, 'kernel':8, 'strides':1, 'padding':'same', 'reg': 0, 'pool':3},\n",
    "    {'filters':160, 'kernel':8, 'strides':1, 'padding':'same', 'reg': 0, 'pool':2},\n",
    "    {'filters':160, 'kernel':8, 'strides':1, 'padding':'same', 'reg': 0, 'pool':2},\n",
    "    {'filters':120, 'kernel':8, 'strides':1, 'padding':'same', 'reg': 0, 'pool':1},\n",
    "    {'filters':120, 'kernel':8, 'strides':1, 'padding':'same', 'reg': 0, 'pool':1},\n",
    "    {'filters':80, 'kernel':8, 'strides':1, 'padding':'same', 'reg': 0, 'pool':''},\n",
    "    {'filters':80, 'kernel':8, 'strides':1, 'padding':'same', 'reg': 0, 'pool':''}\n",
    "]\n",
    "\n",
    "CONV1 = [\n",
    "    {'filters':500, 'kernel':8, 'strides':1, 'padding':'same', 'reg': 0, 'pool':3},\n",
    "    {'filters':500, 'kernel':8, 'strides':1, 'padding':'same', 'reg': 0, 'pool':2},\n",
    "    {'filters':500, 'kernel':8, 'strides':1, 'padding':'same', 'reg': 0, 'pool':1},\n",
    "    {'filters':500, 'kernel':8, 'strides':1, 'padding':'same', 'reg': 0, 'pool':''},\n",
    "    {'filters':500, 'kernel':8, 'strides':1, 'padding':'same', 'reg': 0, 'pool':''}\n",
    "]\n",
    "\n",
    "\n",
    "# generate dataset -------------\n",
    "# ------------------------------\n",
    "print('IN DATA GENERATION')\n",
    "#data, table = load_processed_data(False, not EMBEDDING)\n",
    "\n",
    "print(\"input shape: \", np.shape(data.x_train))\n",
    "\n",
    "\n",
    "\n",
    "# model architecture ------------------------------------------\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "\n",
    "# input and embedding ----------\n",
    "# ------------------------------\n",
    "print('IN MODEL CREATION')\n",
    "if EMBEDDING:\n",
    "\n",
    "    inputlayer = Input(shape=(140,))\n",
    "    network = Embedding(70, 100, input_length=140)(inputlayer)\n",
    "\n",
    "else:\n",
    "    inputlayer = Input(shape=(140 ,70))\n",
    "    network = inputlayer\n",
    "\n",
    "# convolutional layers ---------\n",
    "# ------------------------------\n",
    "\n",
    "for C in CONV1:\n",
    "\n",
    "    # conv layer\n",
    "    network = Conv1D(filters=C['filters'], kernel_size=C['kernel'], \\\n",
    "                     strides=C['strides'], padding=C['padding'], activation='relu', \\\n",
    "                     kernel_regularizer=regularizers.l2(C['reg']))(network)\n",
    "\n",
    "    if type(C['pool']) != int:\n",
    "        continue\n",
    "\n",
    "    # pooling layer\n",
    "    network = MaxPooling1D(C['pool'])(network)\n",
    "\n",
    "# fully connected --------------\n",
    "# ------------------------------\n",
    "network = Flatten()(network)\n",
    "network = Dense(1024, activation='relu')(network)\n",
    "network = Dropout(0)(network)\n",
    "\n",
    "# output\n",
    "ypred = Dense(2, activation='softmax')(network)\n",
    "\n",
    "\n",
    "# training ----------------------------------------------------\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "\n",
    "# callbacks --------------------\n",
    "# ------------------------------\n",
    "\n",
    "# tensorboard\n",
    "print('IN FORMALITIES')\n",
    "TB_DIR = 'logs/' + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\") + '_' + TYPE\n",
    "\n",
    "os.makedirs(TB_DIR)\n",
    "tensorboard = TensorBoard(log_dir=TB_DIR)\n",
    "\n",
    "# early stopping and checkpoint\n",
    "estopping = EarlyStopping(monitor='val_acc', patience=1000)\n",
    "checkpoint = ModelCheckpoint(filepath=MODELPATH, save_best_only=True)\n",
    "\n",
    "# model-------------------------\n",
    "# ------------------------------\n",
    "\n",
    "optimizer = RMSprop(lr=LR)\n",
    "\n",
    "\n",
    "model = Model(inputs=inputlayer, outputs=ypred)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(TB_DIR)\n",
    "print(model.summary())\n",
    "\n",
    "print('IN TRAINING')\n",
    "# fit and run ------------------\n",
    "# ------------------------------\n",
    "try:\n",
    "    hist = model.fit(data.x_train,\n",
    "                     data.y_train,\n",
    "                     validation_data=(data.x_test, data.y_test),\n",
    "                     epochs=10,\n",
    "                     batch_size=250,\n",
    "                     shuffle=False,\n",
    "                     verbose=1,\n",
    "                     callbacks=[estopping, tensorboard])\n",
    "\n",
    "except KeyboardInterrupt:    \n",
    "    print(\"training stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/output/char10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from datetime import datetime\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Conv1D, MaxPooling1D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from functions import *\n",
    "EMBEDDING = True\n",
    "TYPE = 'embedding' if EMBEDDING else 'standard'\n",
    "TB_DIR = 'logs/' + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\") + '_' + TYPE\n",
    "\n",
    "os.makedirs(TB_DIR)\n",
    "tensorboard = TensorBoard(log_dir=TB_DIR)\n",
    "\n",
    "# early stopping and checkpoint\n",
    "estopping = EarlyStopping(monitor='val_acc', patience=1000)\n",
    "model = load_model('/output/char10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2450000 samples, validate on 50000 samples\n",
      "Epoch 1/5\n",
      "2450000/2450000 [==============================] - 352s - loss: 0.2734 - acc: 0.8837 - val_loss: 0.3149 - val_acc: 0.8618\n",
      "Epoch 2/5\n",
      "2450000/2450000 [==============================] - 349s - loss: 0.2726 - acc: 0.8848 - val_loss: 0.3003 - val_acc: 0.8739\n",
      "Epoch 3/5\n",
      "2450000/2450000 [==============================] - 349s - loss: 0.2716 - acc: 0.8856 - val_loss: 0.3029 - val_acc: 0.8716\n",
      "Epoch 4/5\n",
      "2450000/2450000 [==============================] - 349s - loss: 0.2687 - acc: 0.8865 - val_loss: 0.3037 - val_acc: 0.8715\n",
      "Epoch 5/5\n",
      "2450000/2450000 [==============================] - 349s - loss: 0.2667 - acc: 0.8875 - val_loss: 0.2979 - val_acc: 0.8749\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    hist = model.fit(data.x_train,\n",
    "                     data.y_train,\n",
    "                     validation_data=(data.x_test, data.y_test),\n",
    "                     epochs=5,\n",
    "                     batch_size=5000,\n",
    "                     shuffle=False,\n",
    "                     verbose=1,\n",
    "                     callbacks=[estopping, tensorboard])\n",
    "\n",
    "except KeyboardInterrupt:    \n",
    "    print(\"training stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/output/char20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_data.txt') as h:\n",
    "    content_test = h.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(content_test)):\n",
    "    content_test[i] = content_test[i].lstrip('1234567890,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cleanup_col(content_test, numbers=True)\n",
    "    # split in arrays of characters\n",
    "char_arrs = [[x for x in y] for y in X_test]\n",
    "\n",
    "    # tokenize\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(char_arrs)\n",
    "\n",
    "    # token sequences\n",
    "seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "    # pad to same length\n",
    "seq = pad_sequences(seq, maxlen=140, padding='post', truncating='post', value=0)\n",
    "X_test = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s     \n"
     ]
    }
   ],
   "source": [
    "ypred = model.predict(X_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((ypred.shape[0],))\n",
    "count = 0\n",
    "for i in range(ypred.shape[0]):\n",
    "    if ypred[i][0] > ypred[i][1]:\n",
    "        y[i] = 1\n",
    "        count += 1\n",
    "    else:\n",
    "        y[i] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4664"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(y, columns=['Prediction'], index = range(1, 10001))\n",
    "sub.index.name = 'Id'\n",
    "sub = sub.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction\n",
       "Id            \n",
       "1           -1\n",
       "2           -1\n",
       "3           -1\n",
       "4            1\n",
       "5           -1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('/output/sample_cnn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
